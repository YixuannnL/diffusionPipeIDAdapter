# This configuration should allow you to train Wan 14b t2v on 512x512x81 sized videos (or varying aspect ratios of the same size), with 24GB VRAM.

# change this
output_dir = '/data/bohong/object_L/diffusion-pipe/data/output'
# and this
dataset = 'examples/dataset.toml'

# training settings
epochs = 1000
micro_batch_size_per_gpu = 1
pipeline_stages = 1
gradient_accumulation_steps = 1
gradient_clipping = 1
warmup_steps = 10

# eval settings
eval_every_n_epochs = 1
eval_before_first_step = true
eval_micro_batch_size_per_gpu = 1
eval_gradient_accumulation_steps = 1

# misc settings
save_every_n_epochs = 1
checkpoint_every_n_minutes = 120
activation_checkpointing = 'unsloth'
partition_method = 'parameters'
save_dtype = 'bfloat16'
caching_batch_size = 1
steps_per_print = 1
video_clip_mode = 'single_beginning'
# blocks_to_swap = 32

# --- Face-ID Loss ---
use_id_loss     = true     # <- 额外字段
id_loss_weight  = 0.3      # λ_id

keep_vae_gpu = true

[model]
type = 'wan'
ckpt_path = '/data/bohong/object_L/model/Wan2.1-T2V-14B'
dtype = 'bfloat16'
transformer_dtype = 'float8'
timestep_sample_method = 'logit_normal'
keep_vae_gpu = true

[adapter]
#type = 'lora'
#rank = 32
#dtype = 'bfloat16'
type           = "video_id"
num_id_tokens  = 16
layers         = [12, 15, 18, 21] # 0: Initial 1:Adapter 所以打印出来的层数会+2
adapter_dim    = 2048
num_layers     = 4
num_heads      = 16
mlp_ratio      = 4
dropout        = 0.0
grid_size      = [8, 8] # 可以调得更密一点
pool_mode      = "grid"

[optimizer]
type = 'AdamW8bitKahan'
lr = 2e-5
betas = [0.9, 0.99]
weight_decay = 0.01
stabilize = false
